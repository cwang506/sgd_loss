{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Softplus #smooth relu\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from utils import generate_polynomial_data\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.nn import MSELoss, BCELoss\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from model import Net, check_loss_landscape\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "suffix = \"1\"\n",
    "\n",
    "n = 20\n",
    "d = 10000\n",
    "generate_data = False\n",
    "usepickle = True\n",
    "\n",
    "coeffs = -1+2*np.random.rand(d, 1)\n",
    "xvals = -1+2*np.random.rand(n)\n",
    "fileend = \".pickle\" if usepickle else \".npy\"\n",
    "\n",
    "if generate_data:\n",
    "    print(\"Generating Data...\")\n",
    "    X, Y = generate_polynomial_data(coeffs, xvals)\n",
    "    #make categorical\n",
    "    inds_pos = np.where(Y>0)\n",
    "    inds_neg = np.where(Y<=0)\n",
    "#     print(Y)\n",
    "    Y[inds_pos] = 1\n",
    "    Y[inds_neg] = 0\n",
    "    with open(\"./datasets/X_categorical_%s%s\" %((\"pickle_\" if usepickle else \"\"), sufix)+fileend, \"wb\") as f:\n",
    "        if usepickle:\n",
    "            pickle.dump(X, f)\n",
    "        else:\n",
    "            np.save(f, X)\n",
    "    with open(\"./datasets/Y_categorical_%s%s\" %((\"pickle_\" if usepickle else \"\"),suffix) + fileend, \"wb\") as f:\n",
    "        if usepickle:\n",
    "            pickle.dump(Y, f)\n",
    "        else:\n",
    "            np.save(f, Y)\n",
    "    with open(\"./datasets/coeffs_categorical_%s%s\" %((\"pickle_\" if usepickle else \"\"),suffix) + fileend, \"wb\") as f:\n",
    "        if usepickle:\n",
    "            pickle.dump(coeffs, f)\n",
    "        else:\n",
    "            np.save(f, coeffs)\n",
    "    \n",
    "else:\n",
    "    with open(\"./datasets/X_categorical_%s%s\" %((\"pickle_\" if usepickle else \"\"),suffix) + fileend, \"rb\") as f:\n",
    "        if usepickle:\n",
    "            X = pickle.load(f)\n",
    "        else:\n",
    "            X = np.load(f)\n",
    "    with open(\"./datasets/Y_categorical_%s%s\" %((\"pickle_\" if usepickle else \"\"),suffix) + fileend, \"rb\") as f:\n",
    "        if usepickle:\n",
    "            Y = pickle.load(f)\n",
    "        else:\n",
    "            Y = np.load(f)\n",
    "    with open(\"./datasets/coeffs_categorical_%s%s\" %((\"pickle_\" if usepickle else \"\"),suffix) + fileend, \"rb\") as f:\n",
    "        if usepickle:\n",
    "            coeffs = pickle.load(f)\n",
    "        else:\n",
    "            coeffs = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subsample to get 50/50 split\n",
    "inds_pos = np.where(Y==1)[0]\n",
    "inds_neg = np.where(Y==0)[0]\n",
    "pos = np.random.choice(inds_pos, size=int(20/2))\n",
    "neg = np.random.choice(inds_neg, size=int(20/2))\n",
    "data_inds = np.concatenate([pos, neg])\n",
    "data_inds.sort()\n",
    "X, Y = X[data_inds], Y[data_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on CPU\n",
      "0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cwang506/.conda/envs/torch-env/lib/python3.8/site-packages/torch/nn/functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\\epochLoss =  0.002"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d346d474551c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_sgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musegpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0musegpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_gd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musegpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0musegpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sgd_loss/python/model.py\u001b[0m in \u001b[0;36mtrain_sgd\u001b[0;34m(self, data, labels, T, lr, usegpu)\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0moptimizer_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m                 \u001b[0moptimizer_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\repoch: {}\\epochLoss =  {:.3f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/torch-env/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/torch-env/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "sgd = True\n",
    "train = True\n",
    "\n",
    "if sgd:\n",
    "    model_path = \"./models/model_sgd_categorical_%s.pt\"%suffix\n",
    "    net = Net(d, epochs = 50, loss = BCELoss(reduction=\"sum\"), categorical = True)\n",
    "else:\n",
    "    model_path = \"./models/model_categorical_%s.pt\"%suffix\n",
    "    net = Net(d, epochs = 20, loss = BCELoss(reduction=\"sum\"), categorical = True)\n",
    "    \n",
    "if train:\n",
    "    usegpu=False\n",
    "    if torch.cuda.is_available() and usegpu:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        print(\"Running on GPU\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    net.to(device)\n",
    "    if sgd:\n",
    "        net.train_sgd(X, Y, 100000, lr = 1e-2, usegpu = usegpu)\n",
    "    else:\n",
    "        net.train_gd(X, Y, 2000, lr = 1e-3, usegpu = usegpu)\n",
    "    torch.save(net.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
